<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">  <!-- IE的设置 -->
    <meta name="viewport" content="width=device-width, inital-scale=1.0"> <!-- 响应式设置 -->
    <title>US technology giants signed a commitment: no artificial intelligence weapon will be developed.</title>
	<script src="http://www.jq22.com/jquery/jquery-1.10.2.js"></script>
	<link rel="stylesheet" type="text/css" href="../css/public.css"/>
	<link rel="stylesheet" type="text/css" href="../css/style2.css"/>


    <link rel="stylesheet" href="./css/normalize.css"> <!-- CSS资源引入 -->
    <link rel="stylesheet" href="./css/page.css"> <!-- CSS资源引入 -->
    <link rel="shortcut icon" href="./images/logo.png" > <!-- 图标 -->
  </head>
  <body>

  <div class="top"></div>
	<div class="pr navpr">
		<div class="nav pa">
		<div class="w">
			<img class="fl mt9" src="../img/nav-1.png"/>
      <ul class="fl mt16 ml40">
					<li><a href="../index2.html">Index</a></li>
					<li><a href="../news/index2.html">News</a></li>
					<li><a href="../aichutan/index2.html">Explorer</a></li>
					<li><a href="../tushuoai/index2.html">Picture</a></li>
					<li><a href="../zhinengshibie/index2.html">Identification</a></li>
					<li><a href="../jiqikongzhi/index2.html">Machine</a></li>
					<li><a href="../linjunrenwu/index2.html">Leader</a></li>
					<li><a href="../guidianai/index2.html">Campus AI</a></li>
					<li><a href="../xgzz/index2.html">Book</a></li>
					<li><a href="../about/index2.html">About</a></li>
					<div class="clear"></div>
				</ul>
			<div class="nav-btn fr mt17">
				<a class="mr12" href="page27.html">中文</a>|
				<a class="ml10" href="page28.html">English</a>			</div>
			<div class="clear"></div>
		</div>
		<script>
	$(function(){
		var a = $('.nav'),
			b =a.offset();
		$(document).on('scroll',function(){
			var	c = $(document).scrollTop();
			if(b.top<=c){
				a.css({'position':'fixed','top':'0px'})
				}else{
					a.css({'position':'absolute','top':'0px'})
					}
			})
		})
	</script>
	</div>
	</div>


    <div class="bj">

      <!-- 中间部分的内容 -->
      <div class="bj-zhong">
        <h1 class="title">US technology giants signed a commitment: no artificial intelligence weapon will be developed.</h1>
        <div class="two">
          <p>Technology executives headed by three co-founders of Musk and DeepMind recently signed a commitment that their company will not develop smart weapons with AI in the future.</p>
          <p>It's an informal global alliance of researchers and executives in the technology field, mainly against the development of AI weapons. The promise warns that when humans use artificial intelligence weapons to "select and touch" targets, if no human intervention is made before the decision to shoot the target, the end result will be moral degradation, and more serious consequences will be harmful to real life. The people who signed the pledge said, "Morally, the decision to end human life should not be entrusted to machines. In fact, if such weapons are to be proliferated in the future, the end result will be to endanger the lives of every country and even everyone.</p>
          <p>The commitment will be presented today at the Stockholm Joint International Conference on Artificial Intelligence 2018 (IJCAI), organized by the Institute for the Future of Life, which aims to "reduce the risk of human survival". The Institute has previously issued personal letters calling on the United Nations to consider so-called automatic weapons or to enact relevant laws and regulations. However, this is the first public commitment in human history to develop such technologies.</p>
          <p>This commitment is also a direct manifestation of the industry's discussion of AI, and the management of high-tech companies has shifted from simple chat to real action to prove their commitment.</p>
          <p>The signatures include Elon Musk, CEO of SpaceX and Tesla; three founders of DeepMind, a subsidiary of Google: Shane Legg, Mustafa Suleyman and Demis Hassabis; Skype founder Jaan Tallinn; and some of the world's most respected and famous AI researchers, including Stuart Russell, Yoshua Bengio, and J u rgen Schmidhuber.</p>
          <p>In a statement, MIT physics professor Tigmarck said AI leaders had changed from simple communication to real action, fulfilling a promise politicians had never done before that the application of AI to military equipment would be strictly limited. "AI weapons are as disgusting and disturbing as biochemical weapons, and they should be treated like biochemical weapons," Tigmark said.</p>
          <p>So far, we have done a lot to get AI weapons to be supported and regulated by international stakeholders, but the reality is that all previous efforts have failed. Relevants who support restrictions on the development of AI weapons believe that some relevant legal regimes should be introduced, similar to the restrictions on chemical weapons. But it should be noted that the boundaries between good and bad are very difficult to distinguish as long as it does not take shape before doing anything. For example, a turret can aim at a person, but it doesn't fire at them, and the decision whether or not to fire is still in the hands of the person.</p>
          <p>They also pointed out that enforcing such laws would be a great challenge because the technology for developing artificial intelligence weapons was already widespread. Fortunately, none of the countries involved in the development of AI technology really want to develop smart weapons at this stage.</p>
          <p>Paul, a military analyst who wrote a book on future wars and artificial intelligence, told the media this year that "there is not enough"capacity"to promote international automatic weapons control. Because there is no core group of Western countries willing to participate, but this group is very important. The former arms embargo was dominated by countries such as Canada and Norway, but their influence was negligible.</p>
          <p>Although the international law governing the development of AI weapons will not be promulgated soon, recent events have shown that customization of this regulation will be faster and faster. The collective act of signing a commitment like today will give impetus to global automatic arms control. Google, for example, helped the Pentagon develop a non-lethal AI UAV, which was then protested by employees. A few weeks later, the company announced that it would never develop AI or weapon-related systems again. Because of Google's attitude toward AI weapons, students at the University of Kaister in South Korea developed AI weapons, and because of strong resistance from the outside world, the president of Kaister finally promised not to develop "automatic weapons against the will of mankind and without artificial control".</p>
          <p>In this case, we all have reason to believe that the relevant groups have not stopped developing military AI devices or other non-lethal tools. But executives of high-tech companies sign a promise not to develop AI weapons, which is better than none.</p>
        </div>

      </div>
      <!-- 中间部分的内容end -->

    </div>
<iframe src="../bottom2.html" width="100%" height="200px" scrolling="No"  noresize="noresize" frameborder="0" id="bottomFrame"></iframe>
  </body>
</html>
