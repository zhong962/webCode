<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">  <!-- IE的设置 -->
    <meta name="viewport" content="width=device-width, inital-scale=1.0"> <!-- 响应式设置 -->
    <title>The relationship between three aspects of artificial intelligence, machine learning and deep learning</title>
	<script src="http://www.jq22.com/jquery/jquery-1.10.2.js"></script>
	<link rel="stylesheet" type="text/css" href="../css/public.css"/>
	<link rel="stylesheet" type="text/css" href="../css/style2.css"/>


    <link rel="stylesheet" href="./css/normalize.css"> <!-- CSS资源引入 -->
    <link rel="stylesheet" href="./css/page.css"> <!-- CSS资源引入 -->
    <link rel="shortcut icon" href="./images/logo.png" > <!-- 图标 -->
  </head>
  <body>

  <div class="top"></div>
	<div class="pr navpr">
		<div class="nav pa">
		<div class="w">
			<img class="fl mt9" src="../img/nav-1.png"/>
      <ul class="fl mt16 ml40">
					<li><a href="../index2.html">Index</a></li>
					<li><a href="../news/index2.html">News</a></li>
					<li><a href="../aichutan/index2.html">Explorer</a></li>
					<li><a href="../tushuoai/index2.html">Picture</a></li>
					<li><a href="../zhinengshibie/index2.html">Identification</a></li>
					<li><a href="../jiqikongzhi/index2.html">Machine</a></li>
					<li><a href="../linjunrenwu/index2.html">Leader</a></li>
					<li><a href="../guidianai/index2.html">Campus AI</a></li>
					<li><a href="../xgzz/index2.html">Book</a></li>
					<li><a href="../about/index2.html">About</a></li>
					<div class="clear"></div>
				</ul>
			<div class="nav-btn fr mt17">
				<a class="mr12" href="page121.html">中文</a>|
				<a class="ml10" href="page122.html">English</a>			</div>
			<div class="clear"></div>
		</div>
		<script>
	$(function(){
		var a = $('.nav'),
			b =a.offset();
		$(document).on('scroll',function(){
			var	c = $(document).scrollTop();
			if(b.top<=c){
				a.css({'position':'fixed','top':'0px'})
				}else{
					a.css({'position':'absolute','top':'0px'})
					}
			})
		})
	</script>
	</div>
	</div>


    <div class="bj">

      <!-- 中间部分的内容 -->
      <div class="bj-zhong">
        <h1 class="title">The relationship between three aspects of artificial intelligence, machine learning and deep learning</h1>
        <div class="two">
          <p>Artificial intelligence is the future. AI is science fiction. Artificial intelligence has penetrated into our daily life. These are all true, of course, depending on what kind of AI you mean. Earlier this year, for example, Google DeepMind's Alpha Go project defeated South Korea's Lee Shih-shih in a world-renowned Go game, using the terms artificial intelligence, machine learning and in-depth learning to explain why DeepMind won. But the three is not the same thing.</p>
          <p>The simplest way to understand the three relationships is to imagine them as a concentric circle, in which artificial intelligence is the largest, and this concept was first introduced; then machine learning, later; and finally in-depth learning, but it is now the source of the explosive development of artificial intelligence, within the scope of the first two.</p>
        </div>
        <div class="one">
          <img src="./pimg/p1211.jpg" width=100% height=auto>
        </div>
        <div class="two">
          <h3>From low tide to prosperity</h3>
          <p>Since computer scientists confirmed the term artificial intelligence at Dartmouth Conferences in 1956, there have been many fantastic ideas about artificial intelligence, and researchers have been working on it. In the decades that followed, artificial intelligence was first touted as the key to a bright future for human civilization, and then abandoned as an overly arrogant fantasy. To be honest, before 2012, AI was in the two place.</p>
          <p>But in the past few years, artificial intelligence has exploded, especially after 2015. Most of this is due to the widespread use of graphics processors (GPUs), which make parallel processing faster, cheaper, and more powerful. In addition, the development of artificial intelligence has benefited from the emergence of almost unlimited storage space and massive data (large data movement): images, text, transaction data, map data, everything.</p>
          <p>Let's look back at how computer scientists made artificial intelligence, which was at a low ebb until 2012, a boom that hundreds of millions of people use every day.</p>
          <h3>Artificial intelligence: human intelligence displayed by machines</h3>
          <p>When the pioneers of artificial intelligence met in Dartmouth, their dream was to build a complex machine with the equivalent of human intelligence through the then emerging computer. This is what we call the "General AI" concept, a magical machine with five (or more) senses, reasoning power, and the way people think. In the movies we've seen countless of these robots, human-friendly C-3POs, and human enemy terminators. General AI machines exist only in movies and science fiction for the simple reason that we can't, at least so far.</p>
          <p>What we can do is to call it "weak AI" (Narrow AI): technology that performs a specific task at a level comparable to, or even superior to, humans. There are many examples of weak AI in reality. These technologies have the side of human intelligence. But how did they do that? Where does intelligence come from? This involves the next concentric circle: machine learning.</p>
          <h3>Machine learning: a way to achieve AI</h3>
          <p>In short, machine learning is to use algorithms to analyze data, learn from it and make inferences or predictions. So unlike traditional handwritten software routines that use specific instruction sets to accomplish specific tasks, we use a lot of data and algorithms to "train" machines to learn how to accomplish tasks. The concepts of machine learning come from early AI researchers. The algorithms that have been developed include decision tree learning, inductive logic programming, reinforcement learning and Bayesian network. As we all know, none of the algorithms mentioned above has achieved the ultimate goal of general AI, and even weak AI has not been realized by these early machine learning methods.</p>
          <p>For many years, computer vision has been one of the best areas of machine learning, although a lot of manual coding is needed to complete the task. Researchers will manually write classifiers, such as edge detection filters, to help programs identify the boundaries of objects; graph detection classifiers to determine whether objects have eight faces; and classifiers to recognize "S-T-O-P". On the basis of these hand-written classifiers, they developed algorithms for understanding images and learning how to determine whether there are stop signs.</p>
          <p>This is a good step, but it's not amazing. Especially when it is foggy, the logo is not very clear, or there will be a tree block. There are also reasons why computer vision and image detection have not reached human standards until recently: they are untenable and error-prone. But time and the correct learning algorithm have changed everything.</p>
          <h3>Deep learning: a technology for machine learning</h3>
          <p>Early machine learning researchers also developed an algorithm called artificial neural networks, but the invention was unknown for decades. Neural networks are inspired by the human brain: the interconnections between neurons. However, the neurons in the human brain can be connected to any neuron within a specific range, and the data propagation in the artificial neural network has to go through different layers and directions.</p>
          <p>For example, you can cut a picture into small pieces and input it into the first layer of the neural network. In the first level, we do the preliminary calculation, and then the neuron sends the data to the second level. The second layer of neurons performs the task, analogizing it to the last layer, and then outputs the final result.</p>
          <p>Each neuron assigns a weight to its input: the correctness and error of the neuron relative to the task performed. The final output is determined by these weights. So let's take a look at the stop sign example mentioned above. The attributes of a stop sign image are subdivided one by one and then "checked" by neurons: shape, color, character, sign size, and motion. The task of the neural network is to determine whether this is a stop sign. It will give you a probability vector, which is actually a guess based on weight. In this example, the system might have 86% of the assurance that the image is a stop sign, 7% of the assurance that it is a speed limit sign, and so on. The network architecture will then tell the neural network whether it is correct or not.</p>
          <p>But this example is a bit ahead of schedule, as AI researchers have mostly shunned neural networks. The concept of neural network appeared very early, but it did not produce a decent "intelligence". The problem is that even the most basic neural networks consume enormous computational resources, so it was not a viable method at the time. But a small group of enthusiastic researchers, led by Professor Geoffrey Hinton of the University of Toronto, insisted on this approach, eventually enabling supercomputers to execute the algorithm in parallel and proving its usefulness. Of course, this is also achieved after the adoption of GPU.</p>
          <p>If we go back to the stop sign example, it's very likely that neural networks are trained to give wrong answers. This shows that we need constant training. It takes tens of thousands of pictures, even millions of pictures, to train until the neuron inputs are weighted so accurately that it can give the correct answer almost every time (whether it's foggy or rainy). Only then can the neural network learn what the stop sign is. Facebook uses neural networks to remember your mother's face; Wu Enda implemented a cat-aware neural network on Google in 2012.</p>
          <p>Wu Enda's innovation is to expand the scale of the neural network, increase the number of layers and neurons of the network, and then run a large number of data training through the system. Wu Enda uses images from 10 million YouTube videos. Wu Enda really did "deep" in deep learning.</p>
          <p>Today, in some cases, machines trained through in-depth learning perform better than humans in image recognition, including looking for cats, recognizing signs of cancer in the blood, and so on. Google's Alpha Go learned Go and trained a lot for the game: constantly playing against itself.</p>
          <h3>Deep learning gives a bright future for artificial intelligence.</h3>
          <p>Deep learning has made many practical applications in machine learning and artificial intelligence. The emergence of deep learning makes it possible for any machine to assist. Driverless cars, better preventive care, and even better movie recommendations have been or are about to be realized. Artificial intelligence has become a reality and our future. With the help of in-depth learning, artificial intelligence may even reach the state of science fiction that we have long dreamed of. I guess you will have your own C-3PO, or even terminator, in the future.</p>
        </div>

      </div>
      <!-- 中间部分的内容end -->

    </div>
<iframe src="../bottom2.html" width="100%" height="200px" scrolling="No"  noresize="noresize" frameborder="0" id="bottomFrame"></iframe>
  </body>
</html>
